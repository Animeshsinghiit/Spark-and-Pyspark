{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7876e2",
   "metadata": {},
   "source": [
    "# Pyspark Basics Practise Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddb0034",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/05 01:47:56 WARN Utils: Your hostname, zourner-HP-Laptop-15s-du1xxx resolves to a loopback address: 127.0.1.1; using 10.41.166.28 instead (on interface wlo1)\n",
      "23/01/05 01:47:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/05 01:48:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "<SparkContext master=local[*] appName=RDD_practise>\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext,SparkConf\n",
    "conf=SparkConf().setAppName('RDD_practise').setMaster(\"local[*]\")\n",
    "sc=SparkContext(conf=conf)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128a5678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9, 32, 26, 39, 27, 17, 31, 22, 18]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "randlist=random.sample(range(0,40),10)\n",
    "randlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf607ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 9, 32, 26, 39, 27, 17, 31, 22, 18]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating RDD\n",
    "rdd1=sc.parallelize(randlist,4) # if we do not specify number of partition spark will set it to 2\n",
    "rdd1.collect() # it will print out all the data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06ba4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 9], [32, 26], [39, 27], [17, 31, 22, 18]]\n",
      "[[8, 9], [32, 26]]\n"
     ]
    }
   ],
   "source": [
    "#data distribution in Partitions\n",
    "print(rdd1.getNumPartitions())\n",
    "print(rdd1.glom().collect()) #it will show you where or in which partition data lies\n",
    "print(rdd1.glom().take(2)) # take all data show it in partitions and only show two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae23c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of elements\n",
    "rdd1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c427c428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39, 32, 31]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the three largest values in the data after sorting them in ascending order\n",
    "rdd1.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56af3dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 32, 9, 17, 26, 22, 18, 39, 27, 31]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distinct()\n",
    "rdd1.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "020c1319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08, 0.09, 0.32, 0.26, 0.39, 0.27, 0.17, 0.31, 0.22, 0.18]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map(): maps each element with the function passed and retruns the new transformed RDD\n",
    "rdd2=rdd1.map(lambda c: c/100)\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8e75f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c82df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.08, 0.09], [0.32, 0.26], [0.39, 0.27], [0.17, 0.31, 0.22, 0.18]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.glom().collect() # so we can observe that it gives rdd which is exactly of same number of partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e6c9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3=rdd2.filter(lambda x:x>0.19)#filters the rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9745d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [0.32, 0.26], [0.39, 0.27], [0.31, 0.22]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0f88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repartion the small size data into smaller partitions\n",
    "rdd4=rdd3.repartition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9011464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.39, 0.27, 0.31, 0.22], [0.32, 0.26]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ea1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstration through map : [[9, 10], [10, 11], [33, 34], [27, 28], [40, 41], [28, 29], [18, 19], [32, 33], [23, 24], [19, 20]]\n",
      "Demonstration of same using flatmap : [9, 10, 10, 11, 33, 34, 27, 28, 40, 41, 28, 29, 18, 19, 32, 33, 23, 24, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "#flatmap()\n",
    "print('Demonstration through map :',rdd1.map(lambda x:[x+1,x+2]).collect())\n",
    "print('Demonstration of same using flatmap :',rdd1.flatMap(lambda x:[x+1,x+2]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8eb7d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce()\n",
    "rdd1.reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "838ce637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum : 39\n",
      "minimum : 8\n",
      "standard deviation : 9.533624704172071\n",
      "summation : 229\n"
     ]
    }
   ],
   "source": [
    "# Descriptive Statistics\n",
    "print('maximum :',rdd1.max())\n",
    "print('minimum :',rdd1.min())\n",
    "print('standard deviation :',rdd1.stdev())\n",
    "print('summation :',rdd1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88739339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 58, 66, 88]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapPartitions() : can be better understood as a function to apply particular function to each partition and showcase results for each partition\n",
    "def func(partitions):\n",
    "    sum=0\n",
    "    for item in partitions:\n",
    "        sum+=item\n",
    "    yield sum\n",
    "    \n",
    "rdd1.mapPartitions(func).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e6548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
